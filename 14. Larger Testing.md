# 14. 더 큰 테스트

- 구글에서는 중간 크기와 큰 테스트처럼 더 큰 테스트를 많이 활용하고 있다. 더 큰 테스트들도 건실한 소프트웨어 엔지니어링에 필요한 위험 완화 전략에서 중요한 역할을 한다.
- 세월이 흘러도 효과를 유지하게끔 해주는 모범 사례

## 14.1 더 큰 테스트란?

- 테스트의 크기(size)
  - 작은 크기 테스트: 단일 스레드 또는 단일 프로세스
  - 중간 크기 테스트: 단일 기기
- 테스트의 범위(scope)
  - 단위 테스트
  - 통합 테스트
  - 종단간 테스트: 의존하는 외부 모듈을 직접 이용하며 테스트 대역은 거의 쓰지 않는다.
- 더 큰 테스트의 특성
  - 느릴 수 있다. 구글에서 대규모 테스트의 기본 타임아웃 값은 15분이나 1시간이다. 심지어 몇 시간이나 며칠이 걸리는 테스트도 만들어 활용한다.
  - 밀폐되지 않을 수 있다. 대규모 테스트는 다른 테스트나 최종 사용자와 자원 및 트래픽을 공유하기도 한다.
  - 비결정적일 수 있다. 예컨대 밀폐되지 않은 대규모 테스트라면 다른 테스트나 사용자 상태에 영향을 받을 수 있어서 완벽히 결정적이라고 보장하기가 거의 불가능하다.
- 단위 테스트는 개별 함수, 객체, 모듈에 대한 확신을 심어준다. 반면 더 큰 테스트들은 시스템 전체가 의도대로 동작한다는 확신을 더해주는 역할을 한다. 또한 이들을 자동화해두면 다양하게 확장할 수 있다.

### 14.1.1 충실성

- 더 큰 테스트가 존재하는 첫 번째 이유는 충실성을 높이기 위함이다.
- 충실성(fidelity): 테스트가 대상의 실제 행위를 얼마나 충실하게 반영했느냐를 나타내는 속성
  - 테스트 크기와 충실성: 단위테스트 < 단일 프로세스 SUT < 격리된 SUT < 스테이징 < 프로덕션 
- 단위 테스트가 대상 코드를 검증해주는 건 분명하지만 프로덕션 환경에서는 다르게 동작할 것이다.
- 프로덕션은 테스트 충실성이 가장 높은 환경이다.
- 더 큰 테스트의 핵심은 이 사이에서 가장 적합한 지점을 찾아내는 것이다. 충실성이 높아질수록 비용이 커져서 테스트 실패 시 입는 손해도 크기 때문이다.
- 제품을 런칭하기 전에는 현실적인 테스트 트래픽을 만들어내기 쉽지 않다. 단위 테스트용 데이터는 대부분 수작업으로 만들어진다. 그래서 다루는 사례가 몇 안 되고 제작자의 편견이 반영되기 쉽다. 이처럼 데이터에서 누락되어 다루지 못한 시나리오가 테스트의 충실성 하락으로 이어진다.

### 14.1.2 단위 테스트가 손 대기 어려운 영역

#### 1) 부정확한 테스트 대역

- 보통 단위 테스트는 클래스나 모듈 하나를 테스트한다.
- 무겁고 테스트하기 어려운 의존성을 제거하는 용도로 테스트 대역을 많이 쓴다. 하지만 이렇게 하면 실제와 대역의 동작이 일치하지 않을 가능성이 생긴다.
  - 엔지니어가 의존 대상의 실제 동작을 잘못 이해하거나 약속을 오해하는 경우
  - 모의객체는 부실하여 실제 구현이 수정될 때 테스트와 테스트 대상 코드도 함께 수정되어야 한다는 신호를 주지 못한다. 그러므로 각 팀에서 담당 서비스의 가짜 객체를 제공하여 이러한 우려를 제거하는 것이 바람직하다.

#### 2) 설정 문제

- 단위 테스트는 주어진 바이너리 내의 코드를 다룬다. 하지만 일반적으로 이 바이너리는 단독으로 실행될 수 없다 (배포 설정, 시작 스크립트 등 필요).
- 설정 파일에 문제가 있거나, 데이터베이스에 정의된 상태와 다르게 테스트한 후 프로덕션에 배포하면 사용자에게 심각한 문제를 일으킬 수 있다. 단위 테스트만으로는 이러한 호환성 문제를 검증할 수 없다. 그러므로 설정도 코드처럼 버전 관리를 해야 한다.
- 설정도 코드처럼 버전 관리를 하면 버그의 원인으로 관리할 수 있어서 통제 안 되던 외부 위험에서 벗어날 수 있고 더 큰 테스트에 포함시킬 수도 있다.

#### 3) 과부하 시 나타나는 문제

- 단위 테스트는 작고 빨라야 한다. 표준 테스트 실행 인프라에 적합해야 하고 개발자 워크플로에 매끄럽게 융화되어 자주 실행되어야 하기 때문이다.
- 성능, 부하, 스트레스 트스트는 바이너리에 상당한 양의 트래픽을 일으키므로 통상적인 단위 테스트 모델에 녹이기 어렵다 (상당한 양: 초당 수천에서 수백만 번의 쿼리).

#### 4) 예기치 못한 동작, 입력, 부작용

- 단위 테스트의 범위는 작성자의 상상력에 갇히게 된다. 작성자가 예상할 수 잇는 행위와 입력에 한해서 테스트되기 쉽다.
- 사용자들은 엔지니어가 예상하지 못한 문제를 찾아내는 경우가 아주 많다. 이는 예상치 못한 행위를 테스트하는 다른 기술이 필요하다는 방증이다.
- [하이럼의 법칙](http://hyrumslaw.com). 우리가 약속된 모든 기능을 100% 테스트하더라도, 실제 이용자들은 명시된 약속뿐 아니라 눈에 보이는 모든 것을 자유롭게 이용해볼 수 있다.

#### 5) 창발적 행위와 진공효과 (창발적: 전혀 예기치 않은 새로운 행동 양식이 갑자기 나타남)

- 단위 테스트가 다루는 범위는 제한적이며, 이 범위 밖의 행위가 바뀌는 건 알아챌 수 없다.
- 단위 테스트는 빠르고 안정적이게끔 설계하기 때문에 실제로 의존하는 바이너리 혹은 현실 세계의 네트워크와 데이터에 연결했을 때 발생할 수 있는 혼돈은 의도적으로 배제한다.
- 그러므로 속도와 안정성은 매우 뛰어나지만 특정 범주의 결함들은 놓치기 쉽다.

### 14.1.3 더 큰 테스트를 만들지 않는 이유

- 좋은 단위 테스트라면 아래의 특징을 모두 갖춰야 한다.
  - 높은 신뢰성: 결과가 불규칙하면 안 되며 유용한 성공/실패 신호를 제공해야 한다.
  - 빠른 속도: 개발자 워크플로를 방해하지 않을 정도로 빨라야 한다.
  - 높은 확장성: 구글은 변경되는 코드에 영향을 받는 모든 테스트를 서브밋 직전과 직후에 효율적으로 실행할 수 있어야 한다.
- 더 큰 테스트에서는 위와 같은 특징을 하나도 갖추지 못하는 경우도 생긴다 (더 많은 인프라 사용으로 인해 비결정적인 결과가 초래되고 더 오래 걸린다).
- 더 큰 테스트가 극복해야 할 과제
  - 소유권 문제: 단위 테스트는 누가 소유자인지 명확하다. 더 큰 테스트는 다수의 단위에 걸쳐 있으므로 관련된 소유자 역시 많다. 시간이 흐를수록 소유권이 더 모호해진다. 유지보수는 누가 책임지고, 테스트가 실패하면 누가 문제를 진단해야 하는가? 소유권이 명확하지 않다면 테스트는 서서히 부패할 것이다.
  - 표준화 혹은 표준화 부족: 단위 테스트와 달리 더 큰 테스트는 작성하고 실행하고 디버깅하기 위한 인프라와 프로세스가 부실하다. 더 큰 테스트를 수행하는 방식은 시스템 아키텍처에 따라 달라지므로 테스트 유형이 다양하다. 모든 테스트를 수행하는 표준화된 방식이 없으므로 자연스럽게 인프라의 지원을 받지 못한다. 대규모 변경을 진행하는 사람들이 연관된 팀들의 테스트 모두 수행 방법을 파악하도록 하는 방식은 확장성이 떨어진다. 더 큰 테스트는 팀마다 구현 방식이 다르기 때문에 이 팀들의 제품을 통합해 테스트하려면 먼저 호환되지 않는 인프라들부터 통합해야 한다.

### 14.2 더 큰 테스트 @구글

- 구글은 2003년 이전에도 자동화 테스트를 사용했는데, 일반적으로 종단간 테스트와 같이 진짜 큰 규모로 테스트를 수행했다.
- 단위 테스트와 그 외 테스트를 구분하게 된 중요한 진전
  - 테스트 피라미드를 장려했다. 대다수 테스트가 단위 테스트가 되길 원하여 단위 테스트에 집중했다.
  - 훗날 C/J Build를 대신하여 TAP을 공식 지속적 빌드 시스템으로 도입하였다. 

### 14.2.1 더 큰 테스트와 수명

- 더 큰 테스트들은 시간이라는 관점에서 어떤 영향을 주는가?
- 어떤 활동은 코드 기대 수명이 길수록 더 가치를 발하며, 테스트란 기대 수명에 상관없이 의미가 있는 활동이다. 하지만 어떤 테스트가 가장 적합한지는 코드의 기대 수명에 따라 달라진다.
- 단위 테스트는 기대 수명이 몇 시간 이상만 되면 충분히 가치가 있다.
- 작은 스크립트처럼 수명이 몇 분 수준이라면 수동 테스트가 가장 일반적이며, 이 때 테스트 대상은 보통 로컬에서 실행된다.
- 더 큰 테스트들 모두 수명이 더 긴 소프트웨어에 유용하다. 하지만 수명이 길어질수록 주 관심사가 테스트의 유지보수로 옮겨간다. 시간이 주는 이 영향 때문에 '아이스크림 콘'이라는 안티패턴이 생겨났다.
- 개발 초기에 코드가 몇 분 정도만 쓰이고 사라질 거라 판단하여 수동 테스트에 의존하면 수동 테스트들이 누적되어 초기 테스트 포트폴리오 전체를 지배하게 된다.
  - 처음에 구현한 방식 때문에 코드가 단위 테스트를 하기 어렵게 짜여 있다면 자동화할 수 있는 테스트는 오직 종단간 테스트뿐이다.
- 건강한 상태를 오래 유지하는 핵심은 개발 시작 후 며칠 안으로 단위 테스트를 만들어 테스트 피라미드를 쌓기 시작하는 것이다. 그런 다음 수동으로 수행하던 종단간 테스트를 자동화된 통합 테스트로 대체해 피라미드 위층으로 올린다. 구글은 코드를 서브밋하려면 반드시 단위 테스트를 포함하도록 규정하여 해결했다.
- 오랫동안 코드를 건강하게 유지하려면 단위 테스트와 수동 테스트 사이의 간극을 메우는 데 소홀해서는 안 된다.

### 14.2.2 구글 규모에서의 더 큰 테스트

- 규모가 큰 소프트웨어라면 더 큰 테스트가 그만큼 더 필요하고 유용하다. 하지만 작성하고 수행하고 관리하고 디버깅하는 복잡도는 규모가 커질수록 함께 증가한다.
- 종단간 테스트가 필요한 개별 시나리오의 수는 SUT의 구조에 따라 기하급수적으로 혹은 조합의 수만큼 늘어나기 마련이므로 이런 식의 성장은 확장하는 데 한계가 분명하다. 따라서 시스템의 성장에 맞춰 더 큰 테스트들도 지속해서 관리할 수 있으려면 새로운 전략을 모색해야 한다.
- 서비스 규모를 이만큼 키우기 위해 구성요소의 수를 늘려놨기 때문에 더 큰 테스트들을 통해 얻는 가치 역시 커진다. 그리고 이 가치에는 충실성이 큰 영향을 준다.
- 충실성이 낮은 테스트 대역을 사용하면 버그가 생길 가능성이 매우 높으므로 더 큰 테스트들은 원하는 규모에서 잘 작동하면서도 충실성이 상당히 높게 구현하는 게 관건이다.

#### TIP 가능한 한 작은 테스트

- 통합 테스트라 하더라도 가능한 한 작을수록 좋다. 초거대 테스트 하나보다 거대한 테스트 여러 개가 낫다는 말이다.
- 테스트 범위는 SUT의 범위와 관련이 높기 때문에 SUT를 더 작게 만드는 방법을 찾으면 테스트를 더 작게 만드는 데 유리하다.
- 여러 개의 내부 시스템이 관여하는 기능을 테스트하면서 테스트 크기를 작게 만드는 좋은 전략으로 '연쇄 테스트(chain test)'라는 방법이 있다. 기능 전체를 아우르기보다는 작은 통합 테스트들로 나눠 연결한다. 이 때 앞 단계의 테스트 결과를 리포지터리에 저장한 다음, 그다음 단계 테스트의 입력으로 사용한다.

## 14.3 큰 테스트의 구조

- 큰 테스트들은 작은 테스트의 제약조건에 구속받지 않아서 어떤 형태로든 만들 수 있지만, 그래도 대부분은 공통된 패턴을 따른다.
- 큰 테스트를 진행하는 일반적 흐름
  1. 테스트 대상 시스템 확보
  2. 필요한 테스트 데이터 준비
  3. 대상 시스템을 이용해 동작 수행
  4. 행위 검증

### 14.3.1 테스트 대상 시스템

- 대규모 테스트의 핵심은 테스트 대상 시스템(SUT)이다.
- 대규모 테스트에서의 SUT는 대체로 사정이 많이 달라서 하나 이상의 독립된 프로세스에서 수행된다.
- SUT의 형태는 주로 다음 두 요소에 의해 결정된다.
  - 밀폐성: SUT는 현재 테스트하려는 기능과 관련 없는 구성요소를 사용하거나 상호작용하지 못해야 한다. 밀폐성이 높은 SUT는 동시성 문제나 불규칙한 인프라로부터 영향을 적게 받는다.
  - 충실성: SUT는 테스트 중인 프로덕션 시스템을 충실히 반영해야 한다. 충실설이 높은 SUT는 프로덕션 버전과 유사한 바이너리로 구성된다(비슷한 설정, 인프라, 토폴로지).
- 위 두 요소가 충돌할 때가 많은데, 다음 SUT 형태들에서 어떻게 충돌하는지 확인한다.
  - 단일 프로세스 SUT: (프로덕션 시스템에서는 여러 독립 프로세스로 구동되더라도) SUT 전체가 하나의 바이너리로 패키징되고, 나아가 테스트 코드까지 함께 패키징된다. 이러한 테스트-SUT 조합 형태에서 모든 것이 단일 스레드로 실행된다면 '작은' 테스트가 될 수 있다. 하지만 충실성 측면에서는 프로덕션의 토폴로지나 설정과 거리가 가장 먼 테스트가 된다.
  - 단일 머신 SUT: SUT는 (프로덕션과 똑같이) 하나 이상의 독립 바이너리로 구성되며, 테스트도 별도의 바이너리로 만들어진다. 하지만 모두가 하나의 머신에서 구동한다. 구글에서 '중간 크기' 테스트라고 하는 형태이다. 이상적으로는 SUT 바이너리를 비록 로컬에서 실행하더라도 충실성을 높이기 위해 프로덕션 실행 설정을 그대로 사용한다.
  - 다중 머신 SUT: (클라우드에 배포된 프로덕션과 비슷하게) SUT를 여러 머신에 분산시킨다. 단일 머신 SUT보다 충실성이 높지만, 테스트 규모가 커지면서 여러 머신과 그 사이를 잇는 네트워크가 불안정성을 키워 테스트에 예기치 못한 영향을 줄 가능성이 커진다.
  - 공유 환경(스테이징과 프로덕션): SUT를 독립적으로 실행하는 대신 테스트에서 공유 환경을 직접 사용한다. 이미 운용 중인 공유 환경에 얹히는 것이라서 추가 비용이 가장 적게 든다. 하지만 공유 환경을 함께 이용 중인 다른 엔지니어들과 충돌할 수 있으므로 테스트만을 위해 임의로 변경할 수 없고 정상적인 배포 워크플로를 따라 코드가 해당 환경에 배포될 때까지 기다려야 한다. 또한 프로덕션 환경일 경우 최종 사용자에게 영향을 줄 위험이 있다.
  - 하이브리드: 어떤 SUT는 혼합된 형태를 띤다. SUT의 구성요소 중 일부는 독립적으로 실행하고, 다른 일부는 공유 환경에서 가동 중인 서비스와 상호작용하는 식이다. 예컨대 테스트할 대상 기능은 직접 실행하지만 백엔드가 공유되고 있을 수 있다. 구글처럼 빠르게 확장되는 회사는 상호 연결된 서비스가 매우 많아서 모든 서비스 각가을 여러 벌 복사해서 실행하는 것이 사실상 불가능하다. 그래서 어느 정도의 하이브리드화는 피할 수 없다.

#### 밀폐된 SUT의 이점

- 큰 테스트에서 SUT는 테스트 신뢰성을 떨어뜨리고 피드백 시간을 늘리는 주범이 될 수 있다.
  - 프로덕션 환경에서의 테스트는 실제 운영 중인 시스템을 이용한다. 테스트 코드가 프로덕션 환경에 배포될 때까지 대기해야 한다. 환경에 릴리즈되는 시점을 테스트 수행자가 직접 통제하지 못한다(SUT가 너무 늦게 준비된다).
  - 흔한 대안으로 거대한 공유 스테이징 환경을 만들고 테스트를 그 안에서 실행하는 방법이 있다. 테스트용 코드가 공유 환경에 반영된 후에야 테스트를 할 수 있다는 한계가 여전하다.
  - 다른 안으로 엔지니어가 스테이징 환경에서 사용할 수 있는 시간을 예약해두고 그 시간 동안은 계류 중인 코드를 배포하고 테스트를 실행해볼 수 있도록 하는 방법도 있다. 환경 자체, 사용자 수, 사용자들 사이의 충돌 가능성이 급속도로 커지기 때문에 엔지니어 수나 서비스 수가 늘어나면 지속하기 어려운 방법이다.
  - 클라우드에서 격리된 영역을 만들거나 머신을 밀폐할 수 있는 환경을 구축하고 그 안에 SUT를 배포하는 방법도 있다. 이러한 환경이 갖춰지면 충돌 걱정이나 시간 예약 없이 코드를 릴리즈할 수 있다.
- 테스트 데이터를 최종 사용자가 발견할 가능성을 항상 염두에 두고 대비해야 한다.

#### 문제 경계에서 SUT 크기 줄이기

- 테스트를 하다 보면 웬만해서는 피해야 할 고통스러운 경계가 존재한다. 프론트엔드와 백엔드가 만나는 경계가 대표적이다. 이 경계를 포괄하는 테스트는 되도록 피해야 한다. UI 테스트는 신뢰하기 어렵고 비용도 많이 들기 때문이다.
  - UI는 look-and-feel 차원에서 달라지는 경우가 잦아서, 실제 동작은 완전해도 UI 테스트를 깨지기 쉽게 만든다.
  - UI는 주로 비동기 방식으로 반응하기 때문에 테스트하기 어렵다.
- 서비스 UI를 백엔드까지 포함시켜 종단간으로 테스트해보는 것도 의미가 있지만, 이런 테스트는 유지보수 비용이 너무 크다.
  - 만약 백엔드가 공개 API를 제공한다면 테스트를 UI/API 경계에서 나누고, 종단간 테스트는 공개 API를 이용해 수행하는 편이 훨씬 쉽다. UI가 웹 브라우저든 CLI든 데스크톱 혹은 모바일 앱이든 모두 마찬가지이다.
- 또 다른 경계로 서드파티 의존성을 들 수 있다. 서드파티 시스템은 대체로 테스트를 위한 공유 환경을 따로 제공하지 않고, 서드파티로 보내는 트래픽에 비용이 매겨지는 경우도 있으므로 실제 서드파티 API를 직접 사용하는 자동 테스트는 권장하지 않는다.

#### 기록/재생 프록시

- 모의 객체와 스텁, 똑같은 API를 제공하는 가짜 서버와 프로세스를 이용하면 서버나 프로세스 전체를 대신하는 대역도 만들 수 있다. 그러나 이때 테스트 대역이 원래의 대상과 완전히 똑같이 동작한다는 보장은 없다.
- SUT가 의존하지만 보조적인 서비스라면 테스트 대역으로 대체할 수 있다. 하지만 이 대역이 원래 의존 대상의 실제 동작을 그대로 반영하는지 알 수 있는지는 어떻게 알 수 있는가?
  - 구글 외부에서는 고객 주도 계약(consumer-driven contract) 테스트용 프레임워크를 활용하는 사례가 늘고 있다. 고객과 서비스 제공자 모두가 지켜야 할 계약(명세)을 정의하고, 이 계약을 토대로 자동화된 테스트를 만들어내는 방식이다. 고객이 서비스의 모의 객체를 정의하며 이때 어떤 입력을 주면 어떤 결과를 받게 되는지를 명시한다. 그런 다음 실제 서비스는 이 입력/결과쌍을 실제 테스트에 활용하여 기대한 결과를 반환하는지를 검증한다.
  - 고객 주도 계약 테스트용 도구로는 Pact Contract Testing과 Spring Cloud Contracts가 유명하다. 하지만 구글은 프로토콜 버퍼를 광범위하게 쓰고 있어서 이 두 도구를 활용하지 않는다.
- 구글은 공개 API가 있다면 더 큰 테스트를 실행해 외부 서비스들과의 트래픽을 기록해뒀다가, 이 트래픽을 더 작은 테스트를 수행할 때 재생하는 방법을 사용한다. 더 큰 테스트 혹은 기록 모드 테스트를 포스트서브밋 테스트로 항시 수행하여 트래픽 로그를 생성하고(테스트 통과 시에만 로그 생성), 더 작은 테스트 혹은 재생 모드 테스트를 개발 시 혹은 프리서브밋 테스트로 활용한다.
  - 기록/재생 방식에서 흥미로운 점은 비결정성을 없애기 위해 매칭기(matcher)를 이용하여 요청을 보고 기대하는 응답과 연결시킨다는 것이다. 스텁이나 모의 객체를 사용할 때 인수를 보고 결과 행위를 결정하는 방식과 매우 비슷하다.
  - 새로운 테스트를 추가할 때 혹은 클라이언트의 행위가 크게 달라지면 기록해둔 트래픽과 요청이 더 이상 일치하지 않을 것이므로 재생 모드 테스트가 실패한다. 이 경우 기록 모드 테스트를 엔지니어가 따로 수행하여 새로운 트래픽을 생성해야 한다. 따라서 기록 모드 테스트를 수행하기 쉽고 빠르게 안정되게 만드는 일 역시 중요하다.

### 14.3.2 테스트 데이터

- 테스트에는 데이터가 필요하고, 대규모 테스트라면 두 가지 데이터가 필요하다.
  - 시드 데이터: 테스트 개시 시점의 SUT 상태를 반영하여 SUT를 사전 초기화해주는 데이터
  - 테스트 트래픽: 테스트 수행 과정에서 SUT로 보내는 데이터
- SUT의 상태를 테스트 전에 초기화해두는 작업 예시
  - 도메인 데이터: 어떤 데이터베이슨느 환경 구성용 데이터가 테이블들에 미리 채워져 있어야 한다. 실제 서비스에서 이런 데이터베이스를 이용한다면 적절한 도메인 데이터 없이는 테스트를 제대로 시작할 수 없다.
  - 현실적인 기준선: 현실적인 SUT가 되려면 품질과 양적 측면 모두에서 현실적인 데이터셋이 기본으로 갖춰져 있어야 할 것이다. 예컨대 소셜 미디어의 거대 테스트라면 사전에 현실적인 소셜 그래프가 구축되어 있어야 한다. 다시 말해, 현실적인 프로필을 갖춘 사용자가 충분히 많아야 하고, 동시에 사용자들 사이의 관계 역시 충분히 맺어져 있어야 의미 잇는 테스트를 진행할 수 있다.
  - 데이터 기록 API: 데이터를 기록하는 API가 복잡할 수 있다. 테스트에서 데이터 리포지터리에 직접 쓸 수도 있지만, 이렇게 하면 실제 바이너리가 데이터를 기록할 때 수행하는 트리거나 검사 로직이 수행되지 않는다.
- 데이터 생성 방법
  - 손수 가공한 데이터: 작은 테스트에서처럼 더 큰 테스트용 데이터도 사람이 손수 만들 수 있다. 예컨대 실제 운영 중인 지도 서비스의 데이터를 복사하여 기준으로 삼아 변경 사항을 테스트할 수 있다.
  - 샘플링한 데이터: 운영 중인 서비스에서 복사한 데이터는 너무 거대하여 테스트 목적으로는 적합하지 않을 수 있다. 대신 표본을 추출해 사용하면 테스트 시간이 단축되고 분석하기도 쉬워진다. 테스트 커버리지를 극대화할 수 잇는 최소한의 데이터만 추출해내는 기술을 '스마트 샘플링(smart sampling)'이라 한다.
